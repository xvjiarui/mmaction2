apiVersion: batch/v1
kind: Job # Deployment will automatically restart when killed. Use Pod if not needed
metadata:
  labels:
    k8s-app: research
    user: jiarui
  generateName: 'hpf-{{job_name}}' # replace <your_name> with something that identifies you
  namespace: '{{name_space}}'
spec:
  ttlSecondsAfterFinished: 86400  # Wait one day to delete completed jobs
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: research
        image: gitlab-registry.nautilus.optiputer.net/xvjiarui0826/mmaction2:latest
        imagePullPolicy: Always
        command: ["/bin/sh"] # replace this with your own job execution scripts
        args: ["-c", "rm -rf mmaction2; git clone -b {{branch}} https://github.com/xvjiarui/mmaction2.git; cd mmaction2;
        python setup.py develop; ln -s /data; mkdir -p /exps/mmaction2/work_dirs; {{link}}
        {{script}} --config {{config}} {{py_args}}"]
        resources:
          requests: # Minimum resources needed for the job
            memory: "{{mem}}"
            cpu: "{{ cpus }}"
            nvidia.com/gpu: "{{ gpus }}"
          limits: # Maximum resources can be used for the job
            memory: "{{max_mem}}"
            cpu: "{{max_cpus}}"
            nvidia.com/gpu: "{{ gpus }}"
        volumeMounts:
          - mountPath: /data # the directory you can access your persistent storage in container
            name: data
#          - mountPath: /data_zip # the directory you can access your persistent storage in container
#            name: data-zip
          - mountPath: /exps # the directory you can access your persistent storage in container
            name: exps
          - mountPath: /dev/shm # Crucial for multi-gpu or multi processing jobs -> enlarge shared memory
            name: dshm
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
#                  - key: nautilus.io/group
#                    operator: In
#                    values:
#                      - haosu
                  - key: gpu-type
                    operator: In
                    values:
                      - "1080"
#                      - 1080Ti
#                      - 2080Ti
#                      - titan-xp
#                      - titan-x
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: data
#        - name: data-zip
#          persistentVolumeClaim:
#            claimName: data-zip
        - name: exps
          persistentVolumeClaim:
            claimName: exps
        - name: dshm
          emptyDir:
            medium: Memory
