apiVersion: batch/v1
kind: Job # Deployment will automatically restart when killed. Use Pod if not needed
metadata:
  labels:
    k8s-app: research
    user: jiarui
  generateName: 'sf-{{job_name}}' # replace <your_name> with something that identifies you
  namespace: '{{name_space}}'
spec:
  ttlSecondsAfterFinished: 86400  # Wait one day to delete completed jobs
  template:
    metadata:
      labels:
        config: '{{base_config}}'
    spec:
      restartPolicy: Never
      containers:
      - name: research
        image: gitlab-registry.nautilus.optiputer.net/xvjiarui0826/mmaction2:latest
        imagePullPolicy: Always
        command: ["/bin/sh"] # replace this with your own job execution scripts
        args: ["-c", "rm -rf mmaction2; pip install --upgrade got10k py3nvml; git clone -b {{branch}} https://github.com/xvjiarui/mmaction2.git; cd mmaction2; python setup.py develop;
        ln -s /data; mkdir -p /exps/mmaction2/work_dirs; {{link}} {{wandb}} {{bg_script}}
        python projects/siamfc-pytorch/test_seq_siamfc.py {{config}} {{py_args}}"]
        resources:
          requests: # Minimum resources needed for the job
            memory: "{{mem}}"
            cpu: "{{ cpus }}"
            nvidia.com/gpu: "{{ gpus }}"
            ephemeral-storage: 5Gi
          limits: # Maximum resources can be used for the job
            memory: "{{max_mem}}"
            cpu: "{{max_cpus}}"
            nvidia.com/gpu: "{{ gpus }}"
            ephemeral-storage: 5Gi
        volumeMounts:
          - mountPath: /data # the directory you can access your persistent storage in container
            name: "{{data_path}}"
          - mountPath: /exps # the directory you can access your persistent storage in container
            name: exps
          - mountPath: /dev/shm # Crucial for multi-gpu or multi processing jobs -> enlarge shared memory
            name: dshm
      initContainers:
        - name: test-cuda
          image: gitlab-registry.nautilus.optiputer.net/xvjiarui0826/mmaction2:latest
          imagePullPolicy: Always
          command: ["/bin/sh"] # replace this with your own job execution scripts
          args: ["-c", "python -c 'import torch;assert torch.cuda.device_count() > 0'"]
        - name: init-data
          image: gitlab-registry.nautilus.optiputer.net/prp/gsutil
          command: ["/bin/sh"] # replace this with your own job execution scripts
          args: ["-c", "{{copy_script}} exit 0"]
          volumeMounts:
            - name: src
              mountPath: /mnt/source
            - name: dst
              mountPath: /mnt/dest
      nodeSelector:
        nautilus.io/disktype: nvme
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: gpu-type
                    operator: In
                    values:
                      - "1070"
                      - "1080"
                      - 1080Ti
                      - 2080Ti
                      - titan-xp
                      - titan-x
                      - TITANRTX
#                      - A100
#                      - V100
                      - "3090"
                      - RTX8000
#                  - key: kubernetes.io/hostname
#                    operator: NotIn
#                    values:
#                      - k8s-chase-ci-02.calit2.optiputer.net
      volumes:
#        - name: data
#          persistentVolumeClaim:
#            claimName: data
        - name: dst
          emptyDir: {}
        - name: src
          persistentVolumeClaim:
            claimName: data
        - name: exps
          persistentVolumeClaim:
            claimName: exps
        - name: dshm
          emptyDir:
            medium: Memory
